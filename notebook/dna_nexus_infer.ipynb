{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ab6cd9a-ed99-4f8d-9ad9-399c19ac270b",
   "metadata": {},
   "source": [
    "# Data Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b35b5746-3730-4b17-9d17-f0f1658fead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "root = '/mnt/project/'\n",
    "proj_root = root + 'UKB_Main/yihwang/RegionBAE'\n",
    "brain_root = os.path.join(root, 'Bulk/Brain MRI/T1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111902b-da4b-4e92-9d5e-8543f969df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list()\n",
    "\n",
    "for i in range(10, 60):\n",
    "    files.extend(glob.glob(f'{brain_root}/{i}/*'))\n",
    "\n",
    "print(len(files))\n",
    "print(files[0])\n",
    "print(files[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689fe1fe-1765-4353-9626-b1842fda7c77",
   "metadata": {},
   "source": [
    "### 20263 MRI image visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d992433-1ecb-4603-8668-3f853f04fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nibabel ipywidgets numpy cv2 matplotlib zipfile\n",
    "!pipi install SimpleITK ants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06961d07-9102-42ad-9b17-d4d0fcaf4eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "import zipfile\n",
    "import sys\n",
    "import ants\n",
    "\n",
    "helpers_path = proj_root + 'src/helpers.py'\n",
    "sys.path.append(os.path.abspath(helpers_path))\n",
    "from helpers import *\n",
    "\n",
    "test_20263_zip = '/mnt/project/Bulk/Brain MRI/T1//59/5999855_20263_2_0.zip'\n",
    "# unzip 필요\n",
    "\n",
    "\n",
    "data_20263 = [\n",
    "    'orig.mgz',\n",
    "    'brain.mgz',\n",
    "    'brainmask.mgz',\n",
    "    'FLAIR.mgz',\n",
    "    'norm.mgz',\n",
    "    'T1.mgz',\n",
    "    'wm.mgz',\n",
    "    'aseg.mgz'\n",
    "]\n",
    "\n",
    "for image in data_20263:\n",
    "    path = root_20263 + image\n",
    "    print(path)\n",
    "    orig = nib.load(path)\n",
    "    data = orig.get_fdata()\n",
    "    explore_3D_array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c192b80-6ff0-4776-8445-6daf6ab2b9ac",
   "metadata": {},
   "source": [
    "# Phecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e70526-f6d8-45f9-aeb4-084d44e69061",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = set()\n",
    "files_20252 = []\n",
    "files_20263 = []\n",
    "idx = list()\n",
    "seen = set()\n",
    "for file in files:\n",
    "    file_split = file.split('_')\n",
    "    id = file_split[0].split('/')[-1]\n",
    "    id = int(id)\n",
    "    if id not in seen:\n",
    "        idx.append(id)\n",
    "        seen.add(id)\n",
    "    code = file_split[1]\n",
    "    codes.add(code)\n",
    "    if code == '20252':\n",
    "        files_20252.append(file)\n",
    "    else:\n",
    "        files_20263.append(file)\n",
    "\n",
    "print(codes)\n",
    "print(files_20252[0])\n",
    "print(files_20252[1])\n",
    "print(files_20252[2])\n",
    "print(f'Total number of samples with MRI data: {len(idx)}')\n",
    "print(f'Total number of 20252 data: len(files_20252)') \n",
    "print(f'Total number of 20263 data: len(files_20263)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e3d24-47d3-4883-812e-9135e1eb2cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2586338-5e77-4f5a-a395-fdb48d9475ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "phe_b = 'PheCode_ICD10_withCovar_221012.txt' # 1.6G\n",
    "phe_root = os.path.join(root, 'WGS/Pheno', phe_b) \n",
    "\n",
    "chunk_size = 10000  # 한 번에 읽을 line 수\n",
    "chunks = []\n",
    "for chunk in pd.read_csv(phe_root, sep=' ', chunksize=chunk_size):\n",
    "    chunks.append(chunk)\n",
    "\n",
    "phecode = pd.concat(chunks, ignore_index=True)\n",
    "phecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed57528-d381-4812-964e-69d44ec8f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_mri_phe = phecode.loc[phecode.IID.isin(idx)].reset_index(drop=True)\n",
    "brain_mri_phe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe88d1-669a-4f48-b754-b9b4c406e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_mri_phe_id = brain_mri_phe.set_index('IID', inplace=False)\n",
    "brain_mri_phe_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26d29d-9190-4a90-b253-c0df1f96a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_disease = dict()\n",
    "\n",
    "def code_filtering(data):\n",
    "    unique_roots = []\n",
    "    seen = set()\n",
    "    \n",
    "    for item in data:\n",
    "        root = item.split('.') \n",
    "        value = ''.join(root[1])\n",
    "        if value not in seen:  \n",
    "            unique_roots.append(value)\n",
    "            seen.add(value)\n",
    "    \n",
    "    return unique_roots\n",
    "\n",
    "for eid in brain_mri_phe['IID']:\n",
    "    age = brain_mri_phe[brain_mri_phe['IID']==eid]['Age'].iloc[0]\n",
    "    sex = brain_mri_phe[brain_mri_phe['IID']==eid]['Sex'].iloc[0]\n",
    "    sample = brain_mri_phe_id.loc[eid]\n",
    "    disease_codes = sample[sample > 0].index.tolist()[13:]\n",
    "    filtered_disease_codes = code_filtering(disease_codes)\n",
    "    disease = 1\n",
    "    if len(disease_codes) == 0:\n",
    "        disease = 0\n",
    "    mri_disease[eid] = [age, sex, disease, filtered_disease_codes, disease_codes]\n",
    "\n",
    "# 딕셔너리를 DataFrame으로 변환\n",
    "mri_disease_df = pd.DataFrame([\n",
    "    {'id': key, 'age': value[0], 'sex': value[1], 'disease': value[2], 'filtered_phe_codes': value[3], 'phe_codes': value[4]}\n",
    "    for key, value in mri_disease.items()\n",
    "])\n",
    "mri_disease_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fde79e-75d8-4a28-bc61-b0a28b477376",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_disease_df['disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c1ab4f-585c-403f-a7c1-96f016dadc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_dist_plot(cn=None, disease=None):\n",
    "    if cn:\n",
    "        plt.hist(cn, bins=30, alpha=0.5, label='CN', density=True, edgecolor='black')\n",
    "    if disease:\n",
    "        plt.hist(disease, bins=30, alpha=0.5, label='Disease', density=True, edgecolor='black')\n",
    "    plt.title('Age Distribution by group')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "cn_ages = mri_disease_df['age'][mri_disease_df['disease']==0]\n",
    "disease_ages = mri_disease_df['age'][mri_disease_df['disease']==1]\n",
    "age_dist_plot(cn_ages, disease_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d8e16-137e-4a29-a016-ff6a66a388b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "phe_esm = pd.read_excel(root+'/yihwang/phecode_esm.xlsx', sheet_name=1)\n",
    "phe_esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf42995f-e6e8-416c-a65b-bdfaf3db58fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_group = phe_esm['group'].unique()\n",
    "disease_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efc8b27-7a16-4e81-8455-90179f2c7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_filtering_group(group_name):\n",
    "    group_phe = sorted(phe_esm['phecode'][phe_esm['group']==group_name].tolist())\n",
    "    print(group_phe)\n",
    "\n",
    "    disease_data = dict()\n",
    "    for phecode in group_phe:\n",
    "        disease_name = phe_esm['name'][phe_esm['phecode']==phecode].iloc[0]\n",
    "        print(phecode, disease_name)\n",
    "        filtered_id = id_filtering_single(phecode)\n",
    "        disease_data[phecode] = len(filtered_id)\n",
    "\n",
    "    id_disease_disorders = list()\n",
    "    for key, value in mri_disease.items():\n",
    "        for code in group_phe:\n",
    "            if str(code) in value[3]:\n",
    "                id_disease_disorders.append(key)\n",
    "                break\n",
    "    print(f\"\\nTotal number of {group_name}: {len(id_disease_disorders)}\")\n",
    "\n",
    "    group_plot(disease_data)\n",
    "    \n",
    "    return id_disease_disorders\n",
    "\n",
    "\n",
    "def id_filtering_single(disease_code):\n",
    "    id_disease = list()\n",
    "    disease_name = phe_esm['name'][phe_esm['phecode']==disease_code].iloc[0]\n",
    "    # print(disease_code, disease_name)\n",
    "    \n",
    "    for key, value in mri_disease.items():\n",
    "        if str(disease_code) in value[3]:\n",
    "            id_disease.append(key)\n",
    "            \n",
    "    # print(f\"\\nTotal number of {disease_name}: {len(id_disease)}\")\n",
    "    return id_disease\n",
    "\n",
    "def group_plot(data):\n",
    "    x = list(data.keys())\n",
    "    y = list(data.values())\n",
    "    \n",
    "    # 플롯 그리기\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.xticks(range(min(x), max(x), 1), fontsize=8)\n",
    "    plt.bar(x, y, color='skyblue')  # 막대 그래프를 사용\n",
    "    plt.xlabel('Key')  # x축 레이블\n",
    "    plt.ylabel('Count')  # y축 레이블\n",
    "    plt.title('Count per Key')  # 그래프 제목\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb5e6e-397e-46a1-b9a4-0a3c0ef9da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_neurological_disorders = id_filtering_group(disease_group[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b03212-fefd-420f-a75e-3cce83d4d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_mental_disorders = id_filtering_group(disease_group[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c441b-a5b7-4574-8b42-ff33b00fd7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_circulatory_disorders = id_filtering_group(disease_group[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20bf266-acd5-4e53-982e-9f244b75bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_metabolic = id_filtering_group(disease_group[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95e03b-8b75-4b14-b72c-22f03335d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_diabete = id_filtering_single(250)\n",
    "print(len(id_diabete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3389076-94f4-4141-b19e-99b5d8bc3638",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_digestive = id_filtering_group(disease_group[1]) # 550: 탈장, 531: 식도 질환, 561: 소화기계 관련 증상, 564: 소화 기능 장애, 535: 위 & 십이지장 염증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569328a-a90b-43bb-8595-76d7534ae7b3",
   "metadata": {},
   "source": [
    "# UKBB Alzheimer's Disease Region-Specific Brain Age Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8933c2-3b88-4c76-860d-89e7d345a761",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'id_filtering_single' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m id_ad \u001b[38;5;241m=\u001b[39m \u001b[43mid_filtering_single\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(id_ad))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'id_filtering_single' is not defined"
     ]
    }
   ],
   "source": [
    "id_ad = id_filtering_single(0)\n",
    "print(len(id_ad))\n",
    "age_dist_plot(None, id_ad['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a837f1-54ca-4334-b9a5-b3e5ce9f4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_csv(filtered_id, csv_name):\n",
    "    mri_disease = brain_img_df[brain_img_df['id'].isin(filtered_id)].reset_index(drop=True)\n",
    "    save_path = os.path.join(proj_root, 'data/ukbb_phe_' + csv_name + '.csv')\n",
    "    mri_disease.to_csv(save_path)\n",
    "\n",
    "mk_csv(id_ad, 'ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740237d1-819c-443b-8bab-5eb9ff80cb38",
   "metadata": {},
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03137a70-4cb6-4674-8edb-c08255bdd04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53ce9c4-656e-48f1-a132-b48be30380af",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = proj_root + 'data/ukbb_region/disease'\n",
    "regions = ['caudate', 'cerebellum', 'frontal_lobe', 'insula', 'occipital_lobe', 'parietal_lobe', 'putamen', 'temporal_lobe', 'thalamus']\n",
    "diseases = ['ad']\n",
    "\n",
    "for code in diseases:\n",
    "    ukb_icd = pd.read_csv(phecode_path)\n",
    "\n",
    "    csv_data = {\n",
    "        'subjectID': [],\n",
    "        'imgs': [],\n",
    "        'mask': [],\n",
    "        'age': []\n",
    "    }\n",
    "    \n",
    "    for region in regions:\n",
    "        csv_data[region] = []\n",
    "        csv_data[f'{region}_mask'] = []\n",
    "        \n",
    "    for i in range(50):\n",
    "        subject = ukb_icd['id'][i]\n",
    "    \n",
    "        csv_data['subjectID'].append(ukb_icd['id'][i])\n",
    "        csv_data['age'].append(ukb_icd['Age'][i])\n",
    "        csv_data['imgs'].append(f'{save_path}/{subject}/T1w_registered.nii.gz')\n",
    "        csv_data['mask'].append(f'{save_path}/{subject}/T1w_brain_mask_registered.nii.gz')\n",
    "        csv_data['caudate'].append(f'{save_path}/{subject}/region_1.nii.gz')\n",
    "        csv_data['caudate_mask'].append(f'{save_path}/3068434/region_1_mask.nii.gz')\n",
    "        csv_data['cerebellum'].append(f'{save_path}/{subject}/region_2.nii.gz')\n",
    "        csv_data['cerebellum_mask'].append(f'{save_path}/{subject}/region_2_mask.nii.gz')\n",
    "        csv_data['frontal_lobe'].append(f'{save_path}/{subject}/region_3.nii.gz')\n",
    "        csv_data['frontal_lobe_mask'].append(f'{save_path}/{subject}/region_3_mask.nii.gz')\n",
    "        csv_data['insula'].append(f'{save_path}/{subject}/region_4.nii.gz')\n",
    "        csv_data['insula_mask'].append(f'{save_path}/{subject}/region_4_mask.nii.gz')\n",
    "        csv_data['occipital_lobe'].append(f'{save_path}/{subject}/region_5.nii.gz')\n",
    "        csv_data['occipital_lobe_mask'].append(f'{save_path}/{subject}/region_5_mask.nii.gz')\n",
    "        csv_data['parietal_lobe'].append(f'{save_path}/{subject}/region_6.nii.gz')\n",
    "        csv_data['parietal_lobe_mask'].append(f'{save_path}/{subject}/region_6_mask.nii.gz')\n",
    "        csv_data['putamen'].append(f'{save_path}/{subject}/region_7.nii.gz')\n",
    "        csv_data['putamen_mask'].append(f'{save_path}/{subject}/region_7_mask.nii.gz')\n",
    "        csv_data['temporal_lobe'].append(f'{save_path}/{subject}/region_8.nii.gz')\n",
    "        csv_data['temporal_lobe_mask'].append(f'{save_path}/{subject}/region_8_mask.nii.gz')\n",
    "        csv_data['thalamus'].append(f'{save_path}/{subject}/region_9.nii.gz')\n",
    "        csv_data['thalamus_mask'].append(f'{save_path}/{subject}/region_9_mask.nii.gz')\n",
    "\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    csv_save_path = proj_root + f'data/csv/{code}_region.csv'\n",
    "    df.to_csv(csv_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fc41c-09e0-421b-b9b9-22f906b86eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subject(root, subject, atlas_template_path, save_root, regions, df, trial, tmp_path, skip):\n",
    "    subject = subject\n",
    "    img_dir = os.path.join(root, subject, 'T1/T1_brain_to_MNI.nii.gz')\n",
    "    save_path = os.path.join(save_root, subject)\n",
    "    print(subject, save_path, flush=True)\n",
    "\n",
    "    # save_path가 이미 존재하면 함수 종료\n",
    "    curr_save_path = glob.glob(save_path + '/*')\n",
    "    if os.path.exists(save_path) and len(curr_save_path) == 20:\n",
    "        skip += 1\n",
    "        print(f\"{skip}th Skipping {subject}, as save_path already exists.\", flush=True)\n",
    "        return skip\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    image = ants.image_read(img_dir)\n",
    "    image = ants.resample_image(image, (128, 128, 128), 1, 0)\n",
    "    mask = ants.get_mask(image)\n",
    "\n",
    "    img_path = save_path + '/T1w_registered.nii.gz'\n",
    "    mask_path = save_path + '/T1w_brain_mask_registered.nii.gz'\n",
    "\n",
    "    ants.image_write(image, img_path)\n",
    "    ants.image_write(mask, mask_path)\n",
    "\n",
    "    transformation = ants.registration(\n",
    "        fixed=image,\n",
    "        moving=ants.image_read(atlas_template_path), \n",
    "        type_of_transform='SyN',\n",
    "        outprefix=tmp_path\n",
    "    )\n",
    "    registered_atlas_ants = transformation['warpedmovout']\n",
    "    gc.collect()\n",
    "\n",
    "    for region_idx in range(1, 10):\n",
    "        region_mask = registered_atlas_ants == region_idx\n",
    "        region_mask_dilated = ants.morphology(region_mask, radius=4, operation='dilate', mtype='binary')\n",
    "\n",
    "        extracted_region = image.numpy() * region_mask_dilated.numpy()\n",
    "        extracted_region_ants = ants.from_numpy(extracted_region)\n",
    "\n",
    "        region_path = save_path + f'/region_{region_idx}.nii.gz'\n",
    "        # region_mask_path = save_path + f'/region_{region_idx}_mask.nii.gz'\n",
    "        ants.image_write(extracted_region_ants, region_path)\n",
    "        # ants.image_write(region_mask_dilated, region_mask_path)\n",
    "\n",
    "        del region_mask, region_mask_dilated, extracted_region\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb1ccc5-304c-492a-b7ab-f39b004ffbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_region_df = proj_root + f'data/csv/ad_region.csv'\n",
    "img_save_root = proj_root + f'data/ukbb_region/disease'\n",
    "os.makedirs(img_save_root, exist_ok=True)\n",
    "tmp_path = proj_root + f'data/ukbb_region/tmp'\n",
    "\n",
    "atlas_template_path = '/media/leelabsg-storage1/yein/research/data/template/MNI-maxprob-thr0-1mm.nii.gz'\n",
    "regions = ['caudate', 'cerebellum', 'frontal_lobe', 'insula', 'occipital_lobe', 'parietal_lobe', 'putamen', 'temporal_lobe', 'thalamus']\n",
    "skip = 0 \n",
    "for i in tqdm(range(len(ad_region_df))):\n",
    "    subject = str(df['id'][i])\n",
    "    skip = process_subject(root, subject, atlas_template_path, img_save_root, regions, ad_region_df, tmp_path, skip)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d7679-a69f-4c8f-b2f0-2ca3780fab9b",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29952283-fae0-4d8c-8caa-8ba090e86d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn torch torchsummary torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795ae0f-905e-42dc-94e3-02ea248b4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "dataset_path = proj_root + 'src/dataset.py'\n",
    "sys.path.append(os.path.abspath(dataset_path))\n",
    "from dataset import *\n",
    "\n",
    "CNN_path = proj_root + 'src/CNN.py'\n",
    "sys.path.append(os.path.abspath(CNN_path))\n",
    "from CNN import *\n",
    "\n",
    "CNN_Trainer_path = proj_root + 'src/CNN_Trainer.py'\n",
    "sys.path.append(os.path.abspath(CNN_Trainer_path))\n",
    "from CNN_Trainer import *\n",
    "\n",
    "lr_scheduler = proj_root + 'src/lr_scheduler.py'\n",
    "sys.path.append(os.path.abspath(lr_scheduler))\n",
    "from learning_rate import lr_scheduler as lr\n",
    "\n",
    "early_stopping_path = proj_root + 'src/early_stopping.py'\n",
    "sys.path.append(os.path.abspath(early_stopping_path))\n",
    "from early_stopping import EarlyStopping\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f781d93a-485d-4d8a-9fed-f87f45a012a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting & hypterparameters\n",
    "IMGS = proj_root + f'data/csv/ad_region.csv' # preprocessed global and 9 regions mri paths\n",
    "dataset_df = pd.read_csv(IMGS)\n",
    "DATASET = 'ukbb'\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 40\n",
    "RESULTS_FOLDER = proj_root + f'data/csv/test/ad'\n",
    "MODEL_SAVE_FOLDER = proj_root + 'model'\n",
    "INPUT_SIZE = (1, 128, 128, 128) \n",
    "LEARNING_RATE = 0.0001\n",
    "LEARNING_RATE_Scheduler =1\n",
    "N_WORKERS = 8\n",
    "REGIONS = 0\n",
    "ROI = 'imgs'\n",
    "MODEL_LOAD_FOLDER = proj_root + 'model'\n",
    "MODEL_LOAD = 1\n",
    "MODEL_LOAD_EPOCH = 40\n",
    "# DATA_SIZE = config.data_size\n",
    "DATA_SIZE = len(dataset_df)\n",
    "MODE = 'test'\n",
    "PATIENCE = 0\n",
    "ngpus = torch.cuda.device_count()\n",
    "GPU = ngpus\n",
    "\n",
    "# setting log\n",
    "print(\"=\"* 20, \" Setting \", \"=\"* 20)\n",
    "print(\"Dataset :                 \", DATASET)\n",
    "print(\"Mode :                    \", MODE)\n",
    "print(\"GPU :                     \", GPU)\n",
    "print(\"Number of gpus :          \", ngpus)\n",
    "print(\"Batch size :             \", BATCH_SIZE)\n",
    "print(\"Data size:               \", DATA_SIZE)\n",
    "print(\"Epochs :                 \", EPOCHS)\n",
    "print(\"Learning Rate :          \", LEARNING_RATE)\n",
    "print(\"Early Stopping Patience :\", PATIENCE)\n",
    "print(\"# of Workers  :          \", N_WORKERS)\n",
    "print(\"Region of Interest :     \", ROI)\n",
    "print(\"Model Save Path:         \", MODEL_SAVE_FOLDER)\n",
    "print(\"Loaded Model Epoch:      \", MODEL_LOAD_EPOCH)\n",
    "print(\"=\"* 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68361c40-1fad-42b1-90e5-ecec98ed9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our k-folds\n",
    "kf = KFold(n_splits=4, random_state=7, shuffle=True)\n",
    "cv_num = 0\n",
    "# obtain the indices for our dataset\n",
    "dataset_indices = list(dataset_df.index)[:DATA_SIZE]\n",
    "\n",
    "# loop over each fold\n",
    "for train_indices, valid_indices in kf.split(dataset_indices):\n",
    "\n",
    "    print('\\n<<< StratifiedKFold: {0}/{1} >>>'.format(cv_num+1, 4))\n",
    "    \n",
    "    # create a new dataset for this fold\n",
    "    # train_dataset = Region_Dataset(config.root, dataset_df, train_indices, ROI)\n",
    "    # valid_dataset = Region_Dataset(config.root, dataset_df, valid_indices, ROI)\n",
    "    train_dataset = Region_Dataset(dataset_df, train_indices, ROI)\n",
    "    valid_dataset = Region_Dataset(dataset_df, valid_indices, ROI)    \n",
    "    dataloader_train = DataLoader(train_dataset, \n",
    "                                batch_size=BATCH_SIZE, \n",
    "                                sampler=RandomSampler(train_dataset),\n",
    "                                collate_fn=train_dataset.collate_fn,\n",
    "                                pin_memory=True,\n",
    "                                num_workers=N_WORKERS)\n",
    "    dataloader_valid = DataLoader(valid_dataset, \n",
    "                                batch_size=BATCH_SIZE, \n",
    "                                sampler=SequentialSampler(valid_dataset),\n",
    "                                collate_fn=valid_dataset.collate_fn,\n",
    "                                pin_memory=True,\n",
    "                                num_workers=N_WORKERS)\n",
    "    \n",
    "    print(\"Train Dataset & Validation Dataset size: \", len(dataloader_train), len(dataloader_valid))\n",
    "    print(valid_indices)\n",
    "\n",
    "    # Define model and optimizer\n",
    "    model = CNN(in_channels=1).cuda()\n",
    "    if not GPU:\n",
    "        model = CNN(in_channels=1).to('cpu')\n",
    "    # Apply the weight_initialiation\n",
    "    model.apply(initialize_weights)\n",
    "    model = torch.nn.DataParallel(model) # use with multi-gpu environment\n",
    "    # summary(model, input_size=INPUT_SIZE, device=\"cuda\") # model-summary\n",
    "\n",
    "    if LEARNING_RATE_Scheduler == 0:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=config.weight_decay)\n",
    "        scheduler = None\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "        t_0 = int(len(train_indices) // BATCH_SIZE // 6)\n",
    "        scheduler = lr.CustomCosineAnnealingWarmUpRestarts(optimizer,T_0= t_0, T_up=10, T_mult=2, eta_max=1e-3, gamma=0.5)\n",
    "\n",
    "    # Loss function\n",
    "    mse_criterion = torch.nn.MSELoss()\n",
    "    mae_criterion = torch.nn.L1Loss()\n",
    "    \n",
    "    # ------------------------ Train the model\n",
    "    if MODE == 'train': \n",
    "\n",
    "        # Early Stopping\n",
    "        if PATIENCE == 0:\n",
    "            EARLY_STOPPING = None\n",
    "        else:\n",
    "            EARLY_STOPPING = EarlyStopping(patience=config.patience, verbose=True)\n",
    "\n",
    "        trainer = CNN_Trainer(model=model, \n",
    "                            model_load_folder=MODEL_LOAD_FOLDER,\n",
    "                            model_save_folder=MODEL_SAVE_FOLDER,\n",
    "                            results_folder=RESULTS_FOLDER,\n",
    "                            dataloader_train=dataloader_train, \n",
    "                            dataloader_valid=dataloader_valid, \n",
    "                            dataloader_test=None,\n",
    "                            epochs=EPOCHS, \n",
    "                            optimizer=optimizer, \n",
    "                            early_stopping=EARLY_STOPPING,\n",
    "                            scheduler=scheduler,\n",
    "                            cv_num=cv_num,\n",
    "                            region=ROI,\n",
    "                            model_load=MODEL_LOAD)\n",
    "        # Model Loading\n",
    "        if MODEL_LOAD == 1:\n",
    "            trainer.load(cv_num, MODEL_LOAD_EPOCH, GPU) # pre-trained model load\n",
    "            \n",
    "        train_start = time.time()\n",
    "        trainer.train() # This will create the lists as instance variables\n",
    "\n",
    "        # Now you can access the lists as:\n",
    "        train_mse_list = trainer.train_mse_list\n",
    "        train_mae_list = trainer.train_mae_list\n",
    "        valid_mse_list = trainer.valid_mse_list\n",
    "        valid_mae_list = trainer.valid_mae_list\n",
    "\n",
    "        print(\"train_mse_list: \", train_mse_list)\n",
    "        print(\"train_mae_list: \", train_mae_list)\n",
    "        print(\"valid_mse_list: \", valid_mse_list)\n",
    "        print(\"valid_mae_list: \", valid_mae_list)\n",
    "        train_end = time.time()\n",
    "\n",
    "        print(f\"\\nElapsed time for one epoch in cv: {(train_end - train_start) / 60:.0f} minutes\")\n",
    "    \n",
    "    # ------------------------ Test the model\n",
    "    else:\n",
    "        \n",
    "        pred_age_data = dict()\n",
    "        true_age_data = dict()\n",
    "        feature_data = dict()\n",
    "\n",
    "        results_folder = ''\n",
    "    \n",
    "        for _, v in REGIONS.items():      \n",
    "\n",
    "            model_load_folder = os.path.join(MODEL_LOAD_FOLDER, v)\n",
    "\n",
    "            # model_save folder & results folder related\n",
    "            if MODE == 'test':\n",
    "                results_folder = os.path.join(RESULTS_FOLDER, str(cv_num))\n",
    "            else: # MODE == 'test_tf'\n",
    "                results_folder = os.path.join(RESULTS_FOLDER + '_tf', str(cv_num))\n",
    "\n",
    "            # test_dataset related\n",
    "            test_dataset = Region_Dataset(dataset_df, dataset_indices, v)\n",
    "            dataloader_test = DataLoader(test_dataset, \n",
    "                                        batch_size=BATCH_SIZE, \n",
    "                                        sampler=SequentialSampler(test_dataset),\n",
    "                                        collate_fn=test_dataset.collate_fn,\n",
    "                                        pin_memory=True,\n",
    "                                        num_workers=N_WORKERS)\n",
    "            if (DATASET == 'ukbb' and MODE == 'test') or (DATASET == 'adni' and MODE == 'test_tf'):\n",
    "                dataloader_test = dataloader_valid\n",
    "\n",
    "            trainer = CNN_Trainer(model=model, \n",
    "                                model_load_folder = model_load_folder,\n",
    "                                model_save_folder=MODEL_SAVE_FOLDER,\n",
    "                                results_folder=results_folder,\n",
    "                                dataloader_train=None, \n",
    "                                dataloader_valid=None, \n",
    "                                dataloader_test=dataloader_test,\n",
    "                                epochs=EPOCHS, \n",
    "                                optimizer=optimizer, \n",
    "                                early_stopping=None,\n",
    "                                scheduler=scheduler,\n",
    "                                cv_num=cv_num,\n",
    "                                region=ROI,\n",
    "                                model_load=MODEL_LOAD)\n",
    "\n",
    "            trainer.load(cv_num, MODEL_LOAD_EPOCH, GPU) # pre-trained model load\n",
    "            pred_ages, true_ages, features = trainer.test() # test\n",
    "\n",
    "            pred_age_data.setdefault(v, [])\n",
    "            true_age_data.setdefault(v, [])\n",
    "            feature_data.setdefault(v, [])\n",
    "\n",
    "            pred_age_data[v].extend(pred_ages)\n",
    "            true_age_data[v].extend(true_ages)\n",
    "            feature_data[v].extend(features)\n",
    "\n",
    "        # save the data\n",
    "        trainer.test_age_data_extraction(pred_age_data,\n",
    "                                    true_age_data,\n",
    "                                    feature_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a778866-740d-40b1-8ed0-aeaaa49f8c77",
   "metadata": {},
   "source": [
    "# PAD Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6f5da4-bbb9-490e-a5ef-acf711273242",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn scipy\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regions = {0: 'imgs', 1: 'caudate', 2: 'cerebellum', 3: 'frontal_lobe', 4: 'insula', 5: 'occipital_lobe', 6: 'parietal_lobe', 7: 'putamen', 8: 'temporal_lobe', 9: 'thalamus'}\n",
    "root = RESULTS_FOLDER\n",
    "age_diff_groups = {}\n",
    "cn_size = DATA_SIZE\n",
    "disease_l = 'mental'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db08a1db-f925-445a-9109-7846ab94e554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_correction(true, pred):\n",
    "    reg = LinearRegression().fit(true.reshape(-1, 1), pred) # reshape to 2D array\n",
    "    beta_0 = reg.intercept_\n",
    "    beta_1 = reg.coef_[0]\n",
    "\n",
    "    corrected_pred = (pred - beta_0) / beta_1\n",
    "    return corrected_pred\n",
    "\n",
    "def pickle_load(root):\n",
    "    map = {v: {'pred_ages': [], 'true_ages': []} for _, v in regions.items()}\n",
    "\n",
    "    # true_ages 4-cv model results gathering for averaging them\n",
    "    for cv_num in range(4):\n",
    "        pickel_path = os.path.join(root, str(cv_num), 'true_ages.pkl')\n",
    "        if os.path.exists(pickel_path):\n",
    "            with open(pickel_path, 'rb') as file:\n",
    "                curr_cv = pickle.load(file)  # cv-split size의 dict (region: age_lists)  # age_lists length: 630\n",
    "                for region, age_list in curr_cv.items():\n",
    "                    map[region]['true_ages'] = age_list\n",
    "    \n",
    "    # pred_ages 4-cv model results gathering for averaging them\n",
    "    for cv_num in range(4):\n",
    "        pickle_path = os.path.join(root, str(cv_num), 'pred_ages.pkl')\n",
    "        if os.path.exists(pickle_path):\n",
    "            with open(pickle_path, 'rb') as file:\n",
    "                curr_cv = pickle.load(file)\n",
    "                for region, age_list in curr_cv.items():\n",
    "                    map[region]['pred_ages'].append(age_list)\n",
    "\n",
    "    for region, _ in map.items():\n",
    "        pred_ages_lists = map[region]['pred_ages']\n",
    "        pred_avg_age = [sum(values) / len(values) for values in zip(*pred_ages_lists)]\n",
    "        map[region]['pred_ages'] = pred_avg_age\n",
    "\n",
    "    \n",
    "    for region, age_list in map.items():\n",
    "        print(region, len(map[region]['true_ages']), len(map[region]['pred_ages']))\n",
    "\n",
    "    print(\"=\" * 30)\n",
    "    return map          \n",
    "\n",
    "def age_dist_plot(region, cn, disease):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.hist(cn[region]['true_ages'], bins=30, alpha=0.6, label='CN', density=True, edgecolor='black', color='#2986cc')\n",
    "    plt.hist(disease[region]['true_ages'], bins=30, alpha=0.4, label=disease_l, density=True, edgecolor='black', color='#cc0000')\n",
    "    plt.title('Age Distribution by Group', fontsize=16)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xlabel('Age', fontsize=14)\n",
    "    plt.ylabel('Density', fontsize=14)\n",
    "    plt.legend(loc='upper right', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "def age_dist_plot_single_group(region, group):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.hist(group[region]['true_ages'], bins=30, alpha=0.6, label='True', density=True, edgecolor='black', color='#2986cc')\n",
    "    plt.hist(group[region]['pred_ages'], bins=30, alpha=0.4, label='Pred', density=True, edgecolor='black', color='#ffa833')\n",
    "    plt.hist(group[region]['corrected_pred_ages'], bins=30, alpha=0.4, label='Corrected Pred', density=True, edgecolor='black', color='#cc0000')\n",
    "    plt.title('Age Distribution by Group', fontsize=16)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xlabel('Age', fontsize=14)\n",
    "    plt.ylabel('Density', fontsize=14)\n",
    "    plt.legend(loc='upper right', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "def age_dist_re_counts(region, cn, re_cn):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    # density=True를 제거하여 실제 값이 표시되도록 합니다.\n",
    "    plt.hist(cn[region]['true_ages'], bins=30, alpha=0.6, label='CN', edgecolor='black', color='#2986cc')\n",
    "    plt.hist(re_cn[region]['true_ages'], bins=30, alpha=0.4, label='Resampled_CN', edgecolor='black', color='#ffa833')\n",
    "    plt.title('Age Distribution by Group', fontsize=16)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xlabel('Age', fontsize=14)\n",
    "    plt.ylabel('Counts', fontsize=14)  # \"Density\"를 \"Counts\"로 변경\n",
    "    plt.legend(loc='upper right', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "def age_dist_plot_counts(region, cn, disease):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.hist(cn[region]['true_ages'], bins=30, alpha=0.6, label='CN', edgecolor='black', color='#2986cc')\n",
    "    plt.hist(disease[region]['true_ages'], bins=30, alpha=0.4, label=disease_l, edgecolor='black', color='#cc0000')\n",
    "    plt.title('Age Distribution by Group', fontsize=16)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xlabel('Age', fontsize=14)\n",
    "    plt.ylabel('Counts', fontsize=14)\n",
    "    plt.legend(loc='upper right', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "def age_dist_plot_pred(region, cn, disease):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.hist(cn[region]['pred_ages'], bins=30, alpha=0.6, label='CN', density=True, edgecolor='black', color='#2986cc')\n",
    "    plt.hist(disease[region]['pred_ages'], bins=30, alpha=0.4, label=disease_l, density=True, edgecolor='black', color='#cc0000')\n",
    "    plt.title('Age Distribution by Group', fontsize=16)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xlabel('Age', fontsize=14)\n",
    "    plt.ylabel('Density', fontsize=14)\n",
    "    plt.legend(loc='upper right', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "def age_dist_plot_pred_counts(region, cn, disease):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.hist(cn[region]['pred_ages'], bins=30, alpha=0.6, label='CN', edgecolor='black', color='#2986cc')\n",
    "    plt.hist(disease[region]['pred_ages'], bins=30, alpha=0.4, label=disease_l, edgecolor='black', color='#cc0000')\n",
    "    plt.title('Age Distribution by Group', fontsize=16)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xlabel('Age', fontsize=14)\n",
    "    plt.ylabel('Counts', fontsize=14)\n",
    "    plt.legend(loc='upper right', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "def age_plot(data, region):\n",
    "    true = data[region]['true_ages']\n",
    "    pred = data[region]['pred_ages']\n",
    "    if region == 'imgs':\n",
    "        region = 'global'\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.scatter(true, pred, alpha=0.2)\n",
    "    plt.plot([min(true), max(true)], [min(true), max(true)], color='red')  # y=x line\n",
    "    plt.title(f'{region} ========== True Age and Predicted Age')\n",
    "    plt.xlabel('True_Age')\n",
    "    plt.ylabel('Predicted_Age')\n",
    "    plt.show()\n",
    "\n",
    "def age_plot_corrected(data, region):\n",
    "    true = data[region]['true_ages']\n",
    "    pred = data[region]['pred_ages']\n",
    "    if region == 'imgs':\n",
    "        region = 'global'\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.scatter(true, pred, alpha=0.2)\n",
    "    plt.plot([min(true), max(true)], [min(true), max(true)], color='red')  # y=x line\n",
    "    plt.title(f'{region} ========== True Age and Corrected Predicted Age')\n",
    "    plt.xlabel('True_Age')\n",
    "    plt.ylabel('Predicted_Age')\n",
    "    plt.show()\n",
    "\n",
    "def age_diff_plot(age_diff_dict, regions):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    age_diff_max = max(abs(max(age_diff_dict.values())), abs(min(age_diff_dict.values())))\n",
    "\n",
    "    cmap = plt.get_cmap('coolwarm')\n",
    "    norm = mcolors.Normalize(vmin=-age_diff_max, vmax=age_diff_max)\n",
    "\n",
    "    for region, age_diff in age_diff_dict.items():\n",
    "        color = cmap(norm(age_diff))\n",
    "        ax.barh(region, age_diff, color=color)\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax)\n",
    "    cbar.set_label('PAD (years)')\n",
    "\n",
    "    ax.set_xlabel('Predicted Age Difference (years)')\n",
    "    ax.set_title('Regional Predicted Age Difference (PAD)')\n",
    "    plt.show()\n",
    "\n",
    "# 예측 연령 차이 계산\n",
    "def calculate_age_diff_avg(data, region):\n",
    "    pred_ages = np.array(data[region]['pred_ages'])\n",
    "    true_ages = np.array(data[region]['true_ages'])\n",
    "    return np.mean(pred_ages - true_ages)\n",
    "\n",
    "def calculate_corrected_age_diff_avg(data, region):\n",
    "    corrected_pred_ages = np.array(data[region]['corrected_pred_ages'])\n",
    "    true_ages = np.array(data[region]['true_ages'])\n",
    "    avg_diff = np.mean(corrected_pred_ages - true_ages)\n",
    "    return np.round(avg_diff, 7)\n",
    "\n",
    "def calculate_age_diff_dist(data, region):\n",
    "    corrected_pred_ages = np.array(data[region]['corrected_pred_ages'])\n",
    "    true_ages = np.array(data[region]['true_ages'])\n",
    "    diff = calculate_corrected_age_diff_avg(data, region)\n",
    "\n",
    "    plt.hist(corrected_pred_ages, bins=30, alpha=0.5, label='Predicted', density=True, edgecolor='black', color='red')\n",
    "    plt.hist(true_ages, bins=30, alpha=0.5, label='True', density=True, edgecolor='black', color='grey')\n",
    "    # plt.hist(diff, bins=30, alpha=0.5, label='Difference', density=True, edgecolor='black')\n",
    "    plt.title('Age Difference Distribution')\n",
    "    plt.xlabel('Age Difference')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def cn_resampling(cn, disease):\n",
    "    \n",
    "    new_cn_ages = dict()\n",
    "\n",
    "    for _, reg in regions.items():  \n",
    "        print(reg, flush=True)\n",
    "        \n",
    "        cn_ages_np = np.array(cn[reg]['true_ages'])\n",
    "        disease_ages_np = np.array(disease[reg]['true_ages'])\n",
    "        print(cn_ages_np.size, disease_ages_np.size)\n",
    "        \n",
    "        # disease_ages의 분포를 추정하기 위해 Kernel Density Estimation (KDE) 사용\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=1.0).fit(disease_ages_np.reshape(-1, 1))\n",
    "        \n",
    "        # cn_ages에서 disease_ages의와 비슷한 분포를 가지도록 샘플링\n",
    "        log_densities = kde.score_samples(cn_ages_np.reshape(-1, 1))\n",
    "        probabilities = np.exp(log_densities)\n",
    "        print(f'log_densities: {log_densities}, probabilities: {probabilities}')\n",
    "        \n",
    "        # cn_ages의 샘플링 확률을 disease_ages의 분포에 맞추어 정규화\n",
    "        probabilities /= probabilities.sum()\n",
    "        print(f'regularized probabilities: {probabilities}')\n",
    "        \n",
    "        # cn_ages의에서 disease_ages의와 비슷한 분포를 가지는 sample indices\n",
    "        sampled_indices = np.random.choice(np.arange(len(cn_ages_np)), size=len(disease_ages_np), p=probabilities, replace=False)\n",
    "        print(sampled_indices)\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "        cn_ages_true_np = np.array(cn[reg]['true_ages'])\n",
    "        cn_ages_pred_np = np.array(cn[reg]['pred_ages'])\n",
    "        print(cn_ages_true_np.shape, cn_ages_pred_np.shape, flush=True) # (25656,) (25656,)\n",
    "        \n",
    "        sampled_true_np = cn_ages_true_np[sampled_indices]\n",
    "        sampled_pred_np = cn_ages_pred_np[sampled_indices]\n",
    "       \n",
    "        # 결과 확인\n",
    "        print(f\"Sampled size of True after Resampling: {len(sampled_true_np)}\", flush=True) # 3118\n",
    "        print(f\"Sampled size of Pred after Resampling: {len(sampled_pred_np)}\", flush=True) # 3118\n",
    "        print(\"=\" * 30)\n",
    "\n",
    "        ages = {\n",
    "            'true_ages': list(sampled_true_np),\n",
    "            'pred_ages': list(sampled_pred_np)\n",
    "        }\n",
    "        new_cn_ages[reg] = ages\n",
    "\n",
    "    return new_cn_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9d1c9-39b0-436d-aa5e-6af34f21fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_root = root + f'ukb_{disease_l}'\n",
    "disease_ages = pickle_load(disease_root)\n",
    "disease_len = len(disease_ages['imgs']['true_ages'])\n",
    "print(disease_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198c5e59-2238-4b62-828b-2710ede49d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 지역에 대한 예측 연령 차이 계산\n",
    "age_diff_dict = {}\n",
    "age_diff_groups[disease_l] = dict()\n",
    "\n",
    "for key, region in regions.items():\n",
    "    region_n = region\n",
    "    if region == 'imgs':\n",
    "        region_n = 'global'\n",
    "    age_plot(disease_ages, region)\n",
    "    age_plot_corrected(disease_ages, region)\n",
    "    age_diff_dict[region_n] = calculate_corrected_age_diff_avg(disease_ages,region)\n",
    "    age_diff_groups[disease_l][region_n] = age_diff_dict[region_n]\n",
    "\n",
    "# 시각화\n",
    "age_diff_plot(age_diff_dict, regions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a858e2-8cb5-4ce7-bd18-188ce8c398e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_diff_groups['CN'] = {\n",
    "  'global': -0.3092825,\n",
    "  'caudate': -0.0997129,\n",
    "  'cerebellum': -0.0510616,\n",
    "  'frontal_lobe': -0.0776628,\n",
    "  'insula': -0.1058889,\n",
    "  'occipital_lobe': -0.0443206,\n",
    "  'parietal_lobe': -0.067503,\n",
    "  'putamen': -0.086337,\n",
    "  'temporal_lobe': -0.0768889,\n",
    "  'thalamus': -0.0631945\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134eacb1-191d-4392-a484-e144ca38503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_group_age_diff_plot(age_diff_dict, groups, regions):\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    colors = {\n",
    "        groups[0]: '#2986cc',   \n",
    "        groups[1]: '#cc0000'    \n",
    "    }\n",
    "\n",
    "    bar_width = 0.3  \n",
    "    index = np.arange(len(regions))\n",
    "\n",
    "    # 각 그룹에 대해 PAD 값을 시각화\n",
    "    for i, group in enumerate(groups):\n",
    "        pad_values = [age_diff_dict[group][region] for region in regions]\n",
    "        bar_positions = index + i * bar_width\n",
    "        \n",
    "        bars = ax.barh(bar_positions, pad_values, bar_width, label=group, color=colors[group], edgecolor='black')\n",
    "        \n",
    "        # 막대에 값 표시 (애너테이션)\n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            label_x_pos = width + 0.1 if width < 0 else width - 0.1\n",
    "            ax.text(label_x_pos, bar.get_y() + bar.get_height()/2, f'{width:.2f}', \n",
    "                    va='center', ha='center', color='black', fontsize=12)\n",
    "\n",
    "    # y축 정렬 및 스타일 설정\n",
    "    ax.set_yticks(index + bar_width * (len(groups) - 1) / 2)\n",
    "    ax.set_yticklabels(regions, fontsize=14)\n",
    "    ax.set_xlabel('Predicted Age Difference (years)', fontsize=14)\n",
    "    ax.set_title('Regional Predicted Age Difference (PAD) by Group', fontsize=18)\n",
    "    # 범례 순서 뒤집기\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    plt.legend(handles[::-1], labels[::-1], fontsize=14)\n",
    "    \n",
    "    # x축 눈금 폰트 크기 설정\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # 그리드와 스타일 설정\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "regions_l = list(regions.values())\n",
    "regions_l.pop(0)\n",
    "regions_l.insert(0, 'global')\n",
    "regions_l = regions_l[::-1]\n",
    "multi_group_age_diff_plot(age_diff_groups, ['CN', disease_l], regions_l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
